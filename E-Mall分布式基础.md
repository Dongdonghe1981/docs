# E-Mall分布式基础

## 一、环境搭建

#### 1. 安装Linux虚拟机 

1. 安装Vagrant

2. 初始化centos7系统
	
	到`https://app.vagrantup.com/boxes/search` 官方镜像，查找centos版本名，
	
	打开cmd窗口，
	
	- 运行`vagrant init centos/7`
	- 运行`vagrant up`
	- 连接虚拟机 `vagrant ssh`
	- 退出`exit`
	- 启动虚拟机`vagrant up`
	
3. 虚拟机网络配置

   - windows主机`ipconfig`

     ```cmd
     以太网适配器 VirtualBox Host-Only Network:
     
        连接特定的 DNS 后缀 . . . . . . . :
        本地链接 IPv6 地址. . . . . . . . : fe80::8c01:9e48:a45a:e57c%9
        IPv4 地址 . . . . . . . . . . . . : 192.168.137.1
        子网掩码  . . . . . . . . . . . . : 255.255.255.0
        默认网关. . . . . . . . . . . . . :
     ```

   - 修改Vagrantfile文件，跟VirtualBox一个网段的IP设置

     ```txt
       # Create a private network, which allows host-only access to the machine
       # using a specific IP.
        config.vm.network "private_network", ip: "192.168.137.10"
     ```
     
   - 重启虚拟机`vagrant reload`
     
   - 确认IP生效 `ip addr`
   
   - windows主机跟虚拟机互相ping通
   
     ```cmd
     # 主机 -> 虚拟机
     C:\Users\HP>ping 192.168.137.10
     
     正在 Ping 192.168.137.10 具有 32 字节的数据:
     来自 192.168.137.10 的回复: 字节=32 时间<1ms TTL=64
     ```
   
     ```shell
     # 虚拟机 -> 主机
     [vagrant@localhost ~]$ ping 192.168.1.105
     PING 192.168.1.105 (192.168.1.105) 56(84) bytes of data.
     64 bytes from 192.168.1.105: icmp_seq=1 ttl=63 time=0.713 ms
     
     /etc/sysconfig/network-scripts/ifcfg-eth1
     #VAGRANT-BEGIN
     # The contents below are automatically generated by Vagrant. Do not modify.
     NM_CONTROLLED=yes
     BOOTPROTO=none
     ONBOOT=yes
     IPADDR=192.168.137.10
     NETMASK=255.255.255.0 <-add
     GATEWAY=192.168.137.1 <-add
     DNS1=114.114.114.114 <-add
     DNS2=8.8.8.8 <-add
     DEVICE=eth1
     PEERDNS=no
     #VAGRANT-END
     
     #重启网卡
     service network restart 
     
     ping baidu.com
     
     # 修改yum源
     #mv /etc/yum.repos.d/CentOS-Base.repo/etc/yum.repos.d/CentOS-Base.repo.backup
     curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo
     
     #生成缓存
     yum makecache
     ```
   
4. 安装Docker

   centos安装docker的社区版的URL  `https://docs.docker.com/engine/install/centos/`

   - 先卸载已安装的Docker

     ```shell
     sudo yum remove docker \
                       docker-client \
                       docker-client-latest \
                       docker-common \
                       docker-latest \
                       docker-latest-logrotate \
                       docker-logrotate \
                       docker-engine
     ```

   - 安装依赖包，设置docker安装地址
   
     ```shell
     #安装依赖包
     $ sudo yum install -y yum-utils
     #设置docker安装地址
     $ sudo yum-config-manager \
         --add-repo \
         https://download.docker.com/linux/centos/docker-ce.repo
     ```
   
   - 安装docker
   
     ```shell
     sudo yum install docker-ce docker-ce-cli containerd.io
     ```
   
   - 启动docker
   
       ```shell
       $ sudo systemctl start docker
       ```
   
   - 确认docker版本
     
     ```shell
     docker -v
     ```
     
   - 设置开机自动启动
     
     ```shell
     sudo systemctl enable docker
     ```
     
   - 配置镜像加速
     
     ```shell
     sudo mkdir -p /etc/docker 
     cd /etc/docker
     sudo vi daemon.json
     {
     	"registry-mirrors": [
     		"http://hub-mirror.c.163.com",
     		"https://k7da99jp.mirror.aliyuncs.com/",
     		"https://dockerhub.azk8s.cn",
     		"https://registry.docker-cn.com"
      	]
     }
     sudo systemctl restart docker
     docker info
     ```
   
5. 安装mysql
   
   - docker镜像仓库URL   `https://hub.docker.com/`

     mysql容器是一个完整的linux
   
     ```shell
      sudo docker pull mysql:5.7
      su root #密码是vagrant
      docker run -p 3306:3306 --name mysql \ #映射端口 宿主机端口：容器端口 ，--name 容器名 mysql
      -v /mydata/mysql/log:/var/log/mysql \  #将日志文件挂载到主机
      -v /mydata/mysql/data:/var/lib/mysql \  #将数据文件挂载到主机
      -v /mydata/mysql/conf:/etc/mysql \  #将配置文件挂载到主机
   -e MYSQL_ROOT_PASSWORD=123456 \  #root的密码
      -d mysql:5.7
      #mysql容器自动启动
   docker update [容器id] --restart=always
     ```
   
   - 配置mysql
   
     ```shell
     [root@localhost conf]# vi /mydata/mysql/conf/my.conf
     [client]
     default-character-set=utf8
     
     [mysql]
     default-character-set=utf8
     
     [mysqld]
     init_connect='SET collation_connection=utf8_unicode_ci'
     init_connect='SET NAMES utf8'
     character-set-server=utf8
     collation-server=utf8_unicode_ci
     skip-character-set-client-handshake
     skip-name-resolve
     ```
   
     重启mysql   `docker restart mysql`
   
     确认容器里的配置文件修改
   
     ```shell
     root@eb964df2adfc:/etc/mysql# cat my.conf
     ```
   
6. 安装redis

   ```shell
   docker pull redis
   ```

   启动redis镜像

   ```shell
   mkdir -p /mydata/redis/conf
   #提前创建好redis.conf
   touch /mydata/redis/conf/redis.conf
   
   docker run -p 6379:6379 --name redis \
   -v /mydata/redis/data:/data \
   -v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \
   -d redis redis-server /etc/redis/redis.conf
   
   #进入redis的容器的客户端
   docker exec -it redis redis-cli
   
   #mysql容器自动启动
   docker update [容器id] --restart=always
   
   # redis持久化配置，否则重启redis后，redis内存中的数据会丢失
   vi redis.conf
   appendonly yes  #加入该行
   
   ```

#### 2. 开发环境配置

   1. maven

      D:\Environment\apache-maven-3.6.3\conf\settings.xml

      ```xml
          <mirror>
            <id>nexus-aliyun</id>
            <mirrorOf>central</mirrorOf>
            <name>Nexus aliyun</name>
            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
          </mirror> 
      
      
          <profile>
            <id>jdk-1.8</id>
            <activation>
      		<activeByDefault>true</activeByDefault>
              <jdk>1.8</jdk>
            </activation>
      	  <properties>
      		<maven.compiler.source>1.8<maven.compiler.source>
      		<maven.compiler.target>1.8<maven.compiler.target>
      		<maven.compiler.compilerVersion>1.8<maven.compiler.compilerVersion>
      	  </properties>
          </profile>
      ```

2. IDEA配置
   
   - 配置Maven
   - 安装插件 `lombok`和`mybatisx`和`gitee`
   - 安装vscode插件
   
8. 配置git

   配置用户名和邮箱

   码云 `gitee.com`，配置公钥

   测试是否成功：`ssh -T git@gitee.com`

   ```shell
   $ ssh -T git@gitee.com
   The authenticity of host 'gitee.com (212.64.62.174)' can't be established.
   ECDSA key fingerprint is SHA256:FQGC9Kn/eye1W8icdBgrQp+KkGYoFgbVr17bmjey0Wc.
   Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
   Warning: Permanently added 'gitee.com,212.64.62.174' (ECDSA) to the list of known hosts.
   Hi Dongdonghe! You've successfully authenticated, but GITEE.COM does not provide shell access.
   
   ```

#### 3.微服务项目创建

使用IDEA的`spring initalizer`创建微服务项目`emall`，并创建子模块`emall-product`等。

修改`.gitignore`，不必要的文件不进行版本管理。

配置IDEA的VCS，连接到码云，进行版本控制。

#### 4. 生成微服务数据库



## 二、快速开发

#### 1.搭建管理控制台

使用码云上的`人人开源`项目`https://gitee.com/renrenio`，进行快速搭建。

1. 克隆`renren-fast`和`renren-fast-vue`

2. 导入renren-fast使用的数据库，修改数据源配置

3. 安装nodejs，配置npm镜像(已有不需安装，镜像已经配置)，在项目目录下运行`npm install`安装依赖，再运行`npm run dev`

4. 登录管理控制台admin/admin，只能使用Chrome

#### 2.使用`renren-generator`生成代码

#### 3.整合mybatis-plus

## 三、SpringCloud Alibaba

### （一）、Nacos

Nacos :`http://127.0.0.1:8848/nacos`  nacos/nacos

GitHub:`https://github.com/alibaba/spring-cloud-alibaba`

#### Nacos服务注册与发现

1. 引用OpenFeign和nacos

   ```xml
           <dependency>
               <groupId>com.alibaba.cloud</groupId>
               <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
           </dependency>
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-starter-openfeign</artifactId>
           </dependency>
   
   ```

   

2. 编写一个接口，该接口用于调用远程服务

3. 声明接口的方法，调用哪个远程服务的哪个请求

   ```java
   @FeignClient("emall-coupon")
   public interface CouponFeignService {
   
       @RequestMapping("/coupon/coupon/member/list")
       public R membercoupons();
   }
   
   ```

   

4. 开启远程调用功能

   ```java
   @EnableFeignClients(basePackages = "com.wh.emall.member.feign")
   @SpringBootApplication
   @EnableDiscoveryClient
   public class EmallMemberApplication {
   }
   ```

#### Nacos配置中心

1. 引入依赖

   ```xml
           <dependency>
               <groupId>com.alibaba.cloud</groupId>
               <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
           </dependency>
   ```

2. 创建`bootstrap.properties`

      ```properties
      spring.application.name=emall-coupon
      spring.cloud.nacos.config.server-addr=127.0.0.1:8848
      ```

3. 给配置中心添加一个数据集`emall-coupon.properties`。默认规则，[应用名.properties]

4. 给[应用名.properties]添加配置

5. 动态获取配置

      @RefreshScop：给Controller类动态获取配置

      @Value("${配置相的名}")：获取得到配置

         如果配置中心和应用的配置文件都配置了相同的项目，优先使用配置中心的配置

#### Nacos相关概念

##### 1、命名空间

配置隔离

默认是public（保留空间），默认新增的所有配置都在public空间。

1. 开发、测试、生产环境可以利用命名空间进行隔离

   注意：在bootstrap.properties里指定使用的命名空间

```proper
#命名空间的id
spring.cloud.nacos.config.namespace=0c71b54f-c1aa-49de-a66c-68c0419dd9a3
```

2. 每个微服务之间的相互隔离，每个微服务只加载自己的命名空间下的配置。

##### 2、配置集

所有配置的集合

##### 3、配置集ID

类似文件名  Data ID

##### 4、配置分组

默认所有的配置集都属于：DEFAULT_GROUP;

```prop
spring.cloud.nacos.config.group=dev
```

最佳实践：每个微服务创建自己的命名空间，使用配置分组区分环境dev,test,prod

##### 5、同时加载多个配置集

1. 微服务任何配置信息，都可以放到配置中心

2. 在bootstrap.properties说明加载配置中心的哪些配置文件

   ```properties
   spring.cloud.nacos.config.namespace=coupon_ns
   spring.cloud.nacos.config.group=dev
   
   spring.cloud.nacos.config.extension-configs[0].data-id=datasource.yml
   spring.cloud.nacos.config.extension-configs[0].group=dev
   spring.cloud.nacos.config.extension-configs[0].refresh=true
   
   spring.cloud.nacos.config.extension-configs[1].data-id=mybatis.yml
   spring.cloud.nacos.config.extension-configs[1].group=dev
   spring.cloud.nacos.config.extension-configs[1].refresh=true
   
   spring.cloud.nacos.config.extension-configs[2].data-id=other.yml
   spring.cloud.nacos.config.extension-configs[2].group=dev
   spring.cloud.nacos.config.extension-configs[2].refresh=true
   ```

3. 可以通过@Value,@ConfigurationProperties获取配置文件的信息，配置中心优先使用

Nacos官方文档`https://nacos.io/zh-cn/docs/what-is-nacos.html`

### （二） 、SpringCloud Gateway

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: baidu_route
          uri: https://www.baidu.com
          predicates:
            - Query=url,baidu
        - id: qq_route
          uri: https://www.qq.com
          predicates:
            - Query=url,qq
```

## 四、前端

### ES6新特性

1. let声明变量

2. const声明常量（只读常量）

3. 结构表达式

   ```js
   // 数组结构
   let arr = [1,2,3];
   let [a,b,c] = arr;
   
   //对象结构
   const person = {
       name: "jack",
       age: 21,
       language: ['java','js','css']
   }
   const {name,age,language} = person;
   const {name:abc,age,language} = person; //将name的值赋给abc
   ```

4. 字符串扩展

   ```js
   str.startsWith("");
   str.endsWith("");
   str.includs("");
   ```

5. 字符串模板

   ```js
   let str = `<div>
   				<span>hello world<span>
   		   </div>`;
   ```

6. 字符串插入表达式，变量名写在${}中

   ```js
   let inf = `我是${name},今年${age}了。`;
   ```

7. 函数参数默认值

   ```js
   function add(a,b=1){
      return a + b;
   }
   ```

8. 函数不定参数个数

   ```js
   function add(...values){
       return values.length;
   }
   ```

9. 箭头函数

   ```js
   var print = obj => console.log(obj);
   print("hello");
   var sum = (a,b) => a+b;
   sum(1,3);
   var hello = ({name}) => {}
   ```

10. 对象优化

    ```js
    const person = {
        name: "jack",
        age: 21,
        language: ['java','js','css']
    }
    Object.keys(person);
    Object.values(person);
    Object.entries(person);
    
    //assign
    const target = {a:1};
    const source1 = {b:2};
    const source2 = {c:3};
    Object.assign(target,source1,source2);
    // target = {a:1,b:2,c:3}
    
    // 声明对象简写
    const name = "jack";
    const age = 23;
    const person = {name,age};
    
    // 对象的函数属性简写
    let person = {
        name: "jack",
        eat: food => consol.log(person.name + "is eating " + food),
        eat1: function(food){
            consol.log(this.name + "is eating " + food)
        }
    }
    
    // 对象运算符
    // 拷贝对象（深拷贝）
    let person = { name:"jack",age:15 }
    let someone = { ...person }
    
    // 合并对象
    let age = { age: 15 }
    let name = { name: "jack" }
    let person = { ...age, ...name }
    
    ```

11. map和reduce

    - map()：接收一个函数，将原数组中的所有元素，用这个函数处理后，放入新数组返回

      ```js
      let arr = [ '1','40','33','11' ];
      arr = arr.map((item)=>{
          return item * 2
      })
      arr = arr.map(e => e*2)
      ```

    - reduce()：为数组中的每一个元素依次执行回调函数，不包括数组中被移除或未被赋值的元素

12. promise

13. 模块化

    ```js
    // user.js
    var name = "jack"
    var age = 21
    export {name,age}
    
    // hello.js
    export const util = {
        sum(a,b){
            return a+b
        }
    }
    //export util
    
    // main.js 使用导出的模块
    import {name,age} from "./user.js"
    import util from "./hello.js"
    util.sum(1,2)
    ```

    

## 五、三级分类菜单开发

### （一）前端

1. index.js 修改api请求接口地址

   ```javascript
   //api接口请求地址 配置emall-gateway的地址
   window.SITE_CONFIG['baseUrl'] = 'http://localhost:88/api';
   ```

2. category.vue

   在`views/modules/`下新建`product`文件夹，在文件夹中新建文件catagory.vue

   ```javascript
     methods: {
       getMenus() {
         this.$http({
           url: this.$http.adornUrl("/product/category/list/tree"),
           method: "get"
         }).then(data => {
             console.log("成功获取菜单数据",data);
         });
       }
     },
     //vue创建完成，就执行
     created() {
         this.getMenus();
     }
   ```

3. vscode设置代码片段模板

   `文件`->`首选项`->`代码片段`

   

### （二）后端

1. emall-gateway

   - 新建跨域配置文件`EmallCorsConfiguration.java`

   ```java
   @Configuration
   public class EmallCorsConfiguration {
   
       private CorsConfiguration buildConfig() {
   
           CorsConfiguration corsConfiguration = new CorsConfiguration();
   
           corsConfiguration.addAllowedHeader("*");
           corsConfiguration.addAllowedOrigin("*");
           corsConfiguration.addAllowedMethod("*");
           corsConfiguration.setAllowCredentials(true);
   
           return corsConfiguration;
       }
   
       @Bean
       public CorsWebFilter corsWebFilter() {
           UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
           source.registerCorsConfiguration("/**", buildConfig());
           return new CorsWebFilter(source);
       }
   }
   ```

   - application.yml

   ```yaml
   spring:
     cloud:
       gateway:
         routes:
           - id: product_route
             uri: lb://emall-product
             predicates:
               - Path=/api/product/**
             filters:
               - RewritePath=/api/(?<segment>.*),/$\{segment}
           - id: admin_route
             uri: lb://renren-fast
             predicates:
               - Path=/api/**
             filters:
               - RewritePath=/api/(?<segment>.*),/renren-fast/$\{segment}
   ```

2. renren-fast

   - application.yml

     ```yaml
      # 配置nacos
      cloud:
         nacos:
           discovery:
             server-addr: 127.0.0.1:8848
     ```

   - 启动类加上服务注册注解

     ```java
     @EnableDiscoveryClient
     @SpringBootApplication
     public class RenrenApplication {
     ```

3. emall-product

   - bootstrap.properties

     ```properties
     spring.cloud.nacos.config.server-addr=127.0.0.1:8848
     spring.application.name=emall-product
     spring.cloud.nacos.config.namespace=product_ns
     ```

   - Nacos创建ID为`product_ns`的命名空间

   - application.yml

     ```yaml
       cloud:
         nacos:
           discovery:
             server-addr: 127.0.0.1:8848
     ```

4. 逻辑删除

   - application.yml

     ```yaml
     mybatis-plus:
       global-config:
         db-config:
           logic-delete-value: 1
           logic-not-delete-value: 0
     ```

   - Entity

     ```java
     	/**
     	 * 是否显示[0-不显示，1显示]
     	 */
     	@TableLogic(value = "1",delval = "0")
     	private Integer showStatus;
     ```

## 六、API品牌管理

### OSS云存储

阿里云注册OSS云存储，在`emall-common`工程里导入阿里云存储依赖

前端校验，是校验用户输入的内容。

后端校验，是校验PostMan的输入内容，防止受到攻击。

### JSR303后端校验

### 统一的异常处理 ControllerAdvice

1. 编写异常处理类，使用@ControllerAdvice注解
2. 使用@ExceptionHandler标注方法可以处理的异常

#### 错误列表枚举类

错误码列表，例如10001等

10：通用

​	001：参数格式化校验

11：商品

12：订单

13：购物车

14：物流

#### 自定义校验

1. 编写一个自定义的校验注解

2. 编写一个自定义的校验器，实现`ConstraintValidator`接口

   可以指定多个校验器

   ```java
   @Constraint(validatedBy = {ListValueConstraintValidator.class})
   ```

3. 关联自定义的校验器和自定义的校验注解

接口文档 `https://easydoc.xyz/#/s/78237135`

## 七、API属性分组

子组件通过事件，向父组件传递数据。`emit`

如果Json的属性是空的话，不写入Json，使用`@JsonInclude(JsonInclude.Include.NON_EMPTY)`注解

引入分页插件`PaginationInterceptor`

#### Controller功能

1. 处理请求，接收和校验数据
2. Service接收Controller传来的数据，进行业务处理
3. Controller接收Service处理完的数据，封装页面指定的vo

Mysql 可以读未提交的数据

set session transaction isolation level read uncommitted;

# 高级篇

## 安装ES

`https://www.elastic.co/guide/index.html`官方文档

```shell
docker pull elasticsearch:7.4.2
docker pull kibana:7.4.2

mkdir -p /mydata/elasticsearch/config
mkdir -p /mydata/elasticsearch/data

#ES可以被任何远程的机器访问
echo "http.host: 0.0.0.0" >> /mydata/elasticsearch/config/elasticsearch.yml

chmod -R 777 /mydata/elasticsearch/

docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms64m -Xmx512m" \
-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \
-v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
-d elasticsearch:7.4.2

#测试访问
http://192.168.137.10:9200/

docker run --name kibana -e ELASTICSEARCH_HOSTS=http://192.168.137.10:9200 -p 5601:5601 -d kibana:7.4.2

#测试访问
http://192.168.137.10:5601/
```

#### 索引文档

`POST http://192.168.137.10:9200/customer/external` put和post是`新增`和`修改`请求，id重复的话，就会修改。put必须有id。

```json
post
{
    "name":"wh"
}

reponse 下划线的属性，是元数据
{
    "_index": "customer",
    "_type": "external",
    "_id": "ZKuooXMBEzX7tkwF7u-M",
    "_version": 1,
    "result": "created",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 1,
    "_primary_term": 1
}
```

#### 查询文档

`GET http://192.168.137.10:9200/customer/external/1`

reponse

```json
{
    "_index": "customer",  //在哪个索引
    "_type": "external",   //在哪个类型
    "_id": "1",            //记录id
    "_version": 1,         //版本号
    "_seq_no": 0,          //并发控制字段，每次更新就会+1，用来做乐观锁
    "_primary_term": 1,    //同上，主分片重新分配，如重启，就会变化
    "found": true,
    "_source": {           //查询到的数据内容
        "name": "wh"
    }
}
```

并发修改

`PUT http://192.168.137.10:9200/customer/external/1?if_seq_no=0&if_primary_term=1` 

修改成功_seq_no加1

`Put http://192.168.137.10:9200/customer/external/1?if_seq_no=0&if_primary_term=1`

修改失败，报409错误

查看索引

```json
http://192.168.137.10:9200/_cat/indices
```



#### 更新文档

`POST customer/external/1/_update`

```json
{
    "doc":{
        "name":"wh"
    }
}
```

该种更新方法，如果重复更新的话，会对比原数据，如果相同，`_version`和`_seq_no`不更新，并且result:noop

```json
    "_version": 3,
    "result": "noop",
```

`POST customer/external/1`

```json
{
    "name":"wh2"
}
或者 PUT customer/external/1
```

#### 删除文档或索引

```json
DELETE customer/external/1
DELETE customer
#type 不能删除
```

#### bulk删除API

```json
POST customer/external/_bulk
{"index":{"_id":1}}
{"name":"wh"}
{"index":{"_id":2}}  //index代表插入
{"name":"wh2"}
语法格式
{action:{metadata}}
{request body}
```

```json
POST /_bulk
{"delete":{"_index":"website","_type":"blog","_id":"123"}}
{"create":{"_index":"website","_type":"blog","_id":"123"}}//创建index
{"title":"my blog data1"} //插入的数据
{"index":{"_index":"website","_type":"blog"}} //插入的项目
{"title":"my blog data2"}//插入的数据
```

样本数据

`https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json`

```json
POST /bank/account/_bulk
```

SearchAPI

ES支持两种基本方式的检索

- REST request URI 发送搜索参数（uri+检索参数)

  GET bank/_search?q=*&sort=account_number:asc  //查询所有，按account_number升序

  

- REST request body (uri+请求体)

  ```json
  GET /bank/_search
  {
    "query": { "match_all": {} },
    "sort": [
      { "account_number": "asc" }
    ]
  }
  ```

#### QueryDSL

`https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-boosting-query.html`

全文检索，按照得分进行排序

match_phase 短语匹配

multi_match 多字段匹配

bool组合多条件查询

must,must_not,should,range

filter不会计算相关性得分

精确值（数值）的查询，使用term，文本字段使用match。

字段.keyword（完全匹配）比match_phrase（短语匹配）的更加精确。

aggregations（执行聚合），相当于group by，count，sum等

```json
##搜索address中包含mill的所有人的年龄分布及平均年龄
GET bank/_search
{
  "query": {
    "match": {
      "address": "mill"
    }
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 10
      }
    },
    "ageAvg":{
      "avg": {
        "field": "age"
      }
    }
  }
}
```

```json
##
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "ageAvg": {
      "terms": {
        "field": "age",
        "size": 100
      },
      "aggs": {
        "genderAgg":{
          "terms":{
            "field":"gender.keyword",
            "size":10
          },
          "aggs": {
            "balanceAvg": {
              "avg": {
                "field": "balance"
              }
            }
          }
      },
        "ageBlanceAvg":{
          "avg": {
            "field": "blance"
          }
        }
    }
  }
  }
}
```

Mapping

ES7之后去掉了type的概念

`GET bank/_mapping`查看索引类型

创建索引的mapping

```json
PUT /my-index
{
  "mappings": {
    "properties": {
      "age":    { "type": "integer" },  
      "email":  { "type": "keyword"  }, 
      "name":   { "type": "text"  }     
    }
  }
}
```

添加一个项目

```json
PUT my-index/_mapping
{
  "properties":{
    "employee-id":{
      "type":"keyword",
      "index":false  //不能使用employee-id进行检索
    }
  }
}
```

不能修改已有的mapping，只能创建一个新的mapping，再数据迁移。

```json
POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}
```

#### 分词

安装ik分词器

`https://github.com/medcl/elasticsearch-analysis-ik/releases`

安装

1. 在/mydata/elasticsearch/plugins/下运行 wget <url>

2. unzip *.zip

3. rm -rf *.zip

4. 解压后的目录

   ```shell
   /mydata/elasticsearch/plugins/analysis-ik
   -rwxrwxrwx. 1 root root 263965 May  6  2018 commons-codec-1.9.jar
   -rwxrwxrwx. 1 root root  61829 May  6  2018 commons-logging-1.2.jar
   drwxrwxrwx. 2 root root   4096 Aug  1 06:34 config
   -rwxrwxrwx. 1 root root  54643 Nov  4  2019 elasticsearch-analysis-ik-7.4.2.jar
   -rwxrwxrwx. 1 root root 736658 May  6  2018 httpclient-4.5.2.jar
   -rwxrwxrwx. 1 root root 326724 May  6  2018 httpcore-4.4.4.jar
   -rwxrwxrwx. 1 root root   1805 Nov  4  2019 plugin-descriptor.properties
   -rwxrwxrwx. 1 root root    125 Nov  4  2019 plugin-security.policy
   
   ```

5. cd ../bin                

   elasticsearch plugin list: 既可以列出系统的分词器

6. 重启ES

7. 测试

   ```json
   POST _analyze
   {
     "analyzer": "ik_smart",
     "text":"我的电商项目"
   }
   ```

#### 扩展词库

​	调整ES的内存从128->512。删除原容器，创建新容器。

安装Nginx

docker run -p 80:80 --name nginx -d nginx:1.12

在/mydata下运行docker container cp nginx:/etc/nginx . 从虚拟机上拷贝配置文件



```shell
docker stop nginx
docker rm nginx
mv nginx conf
mkdir nginx
mv conf nginx
# nginx下html的资源可以直接访问
docker run -p 80:80 --name nginx \
-v /mydata/nginx/html:/usr/share/nginx/html \
-v /mydata/nginx/logs:/var/log/nginx \
-v /mydata/nginx/conf:/etc/nginx \
-d nginx:1.15

#在/mydata/nginx/html/es目录项创建fenci.txt，输入要分词的词汇，比如电商
http://192.168.137.10/es/fenci.txt  该URL可以访问

修改/mydata/elasticsearch/plugins/analysis-ik/config/IKAnalyzer.cfg.xml
       <entry key="remote_ext_dict">http://192.168.137.10/es/fenci.txt</entry>

#在kibana里验证
POST _analyze
{
  "analyzer": "ik_smart",
  "text":"我的电商项目"
}
#分词效果,将【电商】作为一个词汇
    {
      "token" : "电商",
      "start_offset" : 2,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 2
    },
```

#### Elasticsearch-Rest-Client

1. 使用9300 TCP连接ES，建立长链接。 	

   Springboot版本不同，transport-api.jar不同，不能适配es版本

   7.x已经不建议使用，ES8以后要废弃

2. 使用9200 HTTP
   - JestClient：非官方，更新慢
   - RestTemplate：模拟发HTTP请求，ES很多操作需要自己封装，比较麻烦
   - HttpClient：同上
   - Elasticsearch-Rest-Client：官方RestClient，封装ES操作，API层次分明，上手简单

导入elasticsearch-rest-high-level-client

```xml
    <properties>
        <elasticsearch.version>7.4.2</elasticsearch.version>
    </properties>

        <dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>elasticsearch-rest-high-level-client</artifactId>
            <version>7.4.2</version>
        </dependency>

```

编写配置类

```java
@Configuration
public class EmallElasticsearchConfig {

    @Bean
    public RestHighLevelClient esRestClient(){
        RestHighLevelClient client = new RestHighLevelClient(
                RestClient.builder(
                        new HttpHost("192.168.137.10", 9200, "http")));
                return client;
    }
}

```

`https://www.elastic.co/guide/en/elasticsearch/client/java-rest/6.8/java-rest-high.html`

测试保存，也可以更新

```java
    @Test
    void indexData() throws IOException {
        IndexRequest request = new IndexRequest("users");
        request.id("1");

        User user = new User();
        user.setAge(21L);
        user.setGender("F");
        user.setUserName("wh");

        request.source(JSON.toJSONString(user), XContentType.JSON);
        IndexResponse indexResponse = restHighLevelClient.index(request, EmallElasticsearchConfig.COMMON_OPTIONS);
    }
```

聚合检索，及结果获取

```java
 @Test
    void searchData() throws IOException {
        SearchRequest request = new SearchRequest();
        request.indices("bank");
        SearchSourceBuilder builder = new SearchSourceBuilder();
        builder.query(QueryBuilders.matchQuery("address","mill"));

        TermsAggregationBuilder ageAgg = AggregationBuilders.terms("ageAgg").field("age").size(10);
        builder.aggregation(ageAgg);

        AvgAggregationBuilder field = AggregationBuilders.avg("balanceAvg").field("balance");
        builder.aggregation(field);

        System.out.println(builder.toString());

        request.source(builder);

        SearchResponse search = restHighLevelClient.search(request, EmallElasticsearchConfig.COMMON_OPTIONS);

        System.out.println(search.toString());

        SearchHits hits = search.getHits();
        SearchHit[] searchHits = hits.getHits();
        for (SearchHit hit : searchHits){
            Account account = JSON.parseObject(hit.getSourceAsString(),Account.class);

            System.out.println(account);
        }

        Aggregations aggregations = search.getAggregations();

        Terms ageAgg1 = aggregations.get("ageAgg");
        for (Terms.Bucket bucket : ageAgg1.getBuckets()) {
            String keyAsString = bucket.getKeyAsString();
            System.out.println(keyAsString);
        }

        Avg balanceAvg = aggregations.get("balanceAvg");
        System.out.println(balanceAvg.getValue());

    }
```

ES是内存数据库，所有检索性能高于Mysql，ES支持集群配置，所以性能不够，机器来凑。

未上架的商品放在mysql中，上架的商品，放到ES中。

## 商品上架功能

ES中保存的数据

```json
sku索引{
    skuId:
    spuId:
    。。。。
}
attr索引{
    spuId:
    attrs:[{尺寸:,CPU,分辨率]
    
}
```

不作为检索条件和聚合的属性，index:false

nested是属性里包含子属性

```json

```

#### Feign调用流程

1. 构造请求数据，将对象转为json
2. 发送请求，执行成功，解码相应数据
3. 执行请求会有重试机制，可以设置是否重试和重试次数。

#### 动静分离

静：图片，JS，CSS等静态资源（以实际文件存在的方式）

动：服务器需要处理的请求

每个微服务都可以独立部署、运行、升级，独立自治，独立DB；技术、架构、业务

#### 模板引擎thymeleaf

1. thymeleaf-starter:关闭缓存

2. 静态资源放在static文件加下，就可以按照路径直接访问

3. 页面放在templates下，直接访问

   spring-boot，访问项目的时候，默认会找index.html    `WebMvcAutoConfiguration.java`

#### devtools

1. 引入devtools

   ```xml
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-devtools</artifactId>
               <optional>true</optional>
           </dependency>
   ```

2. 修改完页面，controller shift f9重新自动编译页面，如果代码配置修改，还是建议重启

#### nginx配置

1. windows主机的host文件`192.168.137.10 emall.com `

2. 在`192.168.137.10`安装nginx，并监听80端口，然后反向代理到`http://192.168.137.1:10000`

   ```
   [root@localhost conf.d]# cat emall.conf
   server {
       listen       80;
       server_name  emall.com;
   
       #charset koi8-r;
       #access_log  /var/log/nginx/host.access.log  main;
   
       location / {
           proxy_pass http://192.168.137.1:10000;
       }
   :
   :
   ```

#### nginx的负载均衡配置

1. 配置上流服务

   ```
   [root@localhost conf]# cat nginx.conf
   http {
       upstream emall {
           server 192.168.137.1:88;
       }
   ```

2. 配置代理到上流服务

   ```
   [root@localhost conf.d]# cat emall.conf
   server {
       listen       80;
       server_name  emall.com;
   
       location / {
           proxy_pass http://emall;
       }
   
   ```

3. emall-gateway的配置，所有访问url中含有emall.com的请求，都转向到emall-product

   ```yaml
           - id: emall_host_route
             uri: lb://emall-product
             predicates:
               - Host=**.emall.com
   ```

4. nginx转发到网关的时候，会丢掉域名地址，修改conf文件，设置Host信息

   ```
   
       location / {
           proxy_set_header Host $host;
           proxy_pass http://emall;
       }
   
   ```

#### 压力测试

性能指标

- 响应时间

  用户从客户端发起请求，到用户接收到响应结束，整个过程锁耗费的时间

- HPS(Hits Per Second)

  每秒点击次数，单位次/秒

- TPS(Transaction Per Second)

  系统每秒处理的交易数，单位笔/秒

- OPS（Query Per Second）

  系统每秒处理的查询数，单位次/秒

一般情况下（TPS）

金融行业：1000~50000

保险行业：100~100000

制造业：10~5000

互联网电子商务：10000 ~ 1000000

互联网中型网站：1000 ~ 50000

互联网小型网站：500 ~ 10000

修改windows端口访问，提高端口刷新频率

visualvm解决插件无法更新

1. 查看jdk版本号.javar -version

2. `http://visualvm.github.io/pluginscenters.html`
3. 安装visual gc插件

docker stats监控各个容器的运行情况

压测时，nginx主要CPU指标提高，内存基本没有变化。

使用JMeter

创建

TestPlan

​    线程组

​         HTTP请求

   	  查看结果树

​         汇总报告

​         聚合报告

| 压测内容                                                     | 压测线程数 | 吞吐量 | 90%相应时间 | 99%相应时间 | URL                                       |
| ------------------------------------------------------------ | ---------- | ------ | ----------- | ----------- | ----------------------------------------- |
| nginx                                                        | 50         | 2335   | 11          | 944         |                                           |
| Gateway                                                      | 50         | 10367  | 8           | 31          |                                           |
| 简单商品服务hello                                            | 50         | 11134  | 8           | 17          | http://192.168.137.1:10000/hello端口10000 |
| Gateway<br>+简单商品服务hello                                | 50         | 4400   | 30          | 125         | http://localhost:88/hello 端口：88        |
| nginx+Gateway+<br>简单商品服务hello                          | 50         | 700    | 27          | 44          | http://emall.com/hello     端口80         |
| 首页一级菜单                                                 | 50         | 270    | 267         | 367         | http://localhost:10000/                   |
| 首页一级菜单（缓存开）                                       | 50         | 290    | 251         | 365         |                                           |
| 首页一级菜单（缓存开，日志调低，DB加索引）                   | 50         | 735    | 105         | 183         |                                           |
| 三级分类                                                     | 50         | 2      | 12014       | 12482       | http://localhost:10000/index/catalog.json |
| 三级分类（缓存开，日志调低，DB加索引）                       | 50         | 7      |             |             |                                           |
| 三级分类（缓存开，日志调低，DB加索引，一次DB全表检索，java过滤） | 50         | 113    | 571         | 896         |                                           |
| 三级分类（缓存开，日志调低，DB加索引，一次DB全表检索，java过滤，Redis缓存） | 50         | 411    | 153         | 217         |                                           |
| 首页全量数据<br>图片，CSS，Js等                              | 50         | 7      |             |             |                                           |
| 首页全量数据<br/>动静分离                                    | 50         | 13     |             |             |                                           |
| 首页全量数据<br/>动静分离+JVM options<br>-Xmx1024m -Xms1024m -Xmn512m(指定新生代（Eden+S1+S2）) | 200        | 15     |             |             |                                           |

- 中间件越多，性能损失越大，大多都损失在网络交互了

- 首页一级菜单：慢的原因：DB查询和thymeleaf渲染

- 三级分类：慢的原因：DB查询
- 业务
  - DB ，模板的渲染速度（缓存开关），静态资源

#### nginx动静分离

1. 以后将所有项目的静态资源都应该放在nginx里面 

2. 规则：/static/**所有请求都由nginx直接返回

3. nginx虚拟机上创建`/mydata/nginx/html/static`目录，将product工程下的static里的index目录拷贝到创建的目录下，删除工程下的目录

4. 修改templates/index.html的静态资源href，在前面加上static(使用ctrl+r进行替换)

   - href="  -> href="/static/

   - <script src=" -> <script src="/static/

   - <img src=" - > <img src="/static/

5. 修改nginx的emall.conf，然后重启docker restart nginx

   ```nginx
   location /static/ {
       root /usr/share/nginx/html;  
       #root指所有请求都到哪个文件夹下匹配,该目录是nginx容器内的目录，实际static是在被挂载的目录
       #-v /mydata/nginx/html:/usr/share/nginx/html \
   }
   ```

6. chrome -> F12 -> Network -> Disable cache 不缓存数据

## 缓存与分布式锁

### 缓存使用

为了系统性能提升，一般都会将部分数据写入缓存中，加速访问。而DB承担数据持久化工作。

哪些数据适合放入缓存？

1. 及时性、数据一致性要求不高（比如物流信息、商品分类信息）
2. 访问量大，且更新频率不高（读多写少）比如商品信息

读模式缓存使用流程

1. 请求，读取缓存中数据，如果命中，就返回结果

2. 如果没命中，查询数据库，将数据放入缓存，返回结果

   ```java
   data = cache.load(id);
   if(data == null){
       data=db.load(id);
       cache.put(id,data);
   }
   return data;
   ```

分布系统，不适合使用本地缓存，会产生重复查询DB和缓存不一致问题。

使用内存中间件，如redis

整合redis

1. 在pom里引入`spring-boot-starter-data-redis`

2. 在application.yml里配置redis的host信息

3. 使用Springboot自动配置好的StringRedisTemplate来操作redis

   ```
   缓存中是数据，都是json字符串，跨语言，跨平台
   ```

大量并发时，redis出现InternalOutOfDirectMemoryError（堆外内存溢出）异常

direct memory是堆外内存，直接操作内存条。 

springboot2.0默认使用lettcue作为操作redis的客户端，它使用netty进行网络通信。lettcue的bug。

如果没有指定堆外内存，就会使用JVM的-Xmx内存，可以通过-Dio.netty.maxDirectMemory设置。

解决方案：不能使用设置去调大内存。

1. 升级lettuce客户端
2. 切换使用jedis

#### 缓存穿透

同一查询请求，如果缓存中没有，则都访问DB，DB压力瞬增 。

解决方法：第一次查询即使是null结果，也写入缓存，并加入短暂过期时间。不然的话，一直从缓存中得到null结果。

#### 缓存雪崩

设置缓存时采用的相同的过期时间，导致大量 缓存同时失效，请求全部转到DB。

解决方案：在原有失效的时间基础上，加一个随机值。

#### 缓存击穿

某个热点key在大量请求前，失效，那么大量请求都查询DB

解决方案：加锁，大量并发，只让一个去查询，其他等待，查到以后释放锁。其他请求获取到锁，先查缓存，就会有数据，不查询DB。

#### 本地锁

用synchronized定义查询方法，或者使用ReentrantLock。所有的组件在springboot容器中是单例的，因此可以锁住单一对象。

```java
Lock lock = new ReentrantLock() ;    
lock.lock();
try {
    cataLogJsonFromDb = getCataLogJsonFromDb();
    redis.opsForValue().set("cataLogJson", JSON.toJSONString(dbjson), 1, TimeUnit.DAYS);
}catch (Exception e){
    log.error(e.getMessage());
}finally {
    lock.unlock();
}
```

```java
synchronized (this){//this是当前对象，确保对象唯一，就是一把锁，是OK的
    data = getCataLogJsonFromDb();
    redis.opsForValue().set("cataLogJson", JSON.toJSONString(data), 1, TimeUnit.DAYS);
}
```



在分布式情况下，本地锁，只能锁住当前服务器的当前进程，不能锁住其他服务器的进程，因此必须使用分布式锁，但效率低。

模拟分布式：把Services中把当前的产品服务拷贝一份，在Program arguments:中设置--server.port=10001，多拷贝几个，启动服务，可以在nacos中看到服务列表的实例数。JMeter里设置为给Nginx发送请求emall.com，端口80

分布式锁，代码

```java
String uuid = UUID.randomUUID().toString();
Boolean lock = stringRedisTemplate.opsForValue().setIfAbsent("lock", uuid ,300,TimeUnit.SECONDS);
if (lock){
    try {
        Map<String, List<Catelog2Vo>> cataLogJsonFromDb = getCataLogJsonFromDb();
    }finally {
        String luaScript = "if redis.call('get',KEYS[1]) == ARGV[1] then  return redis.call('del',KEYS[1]) else return 0 end";
        DefaultRedisScript<Long> script = new DefaultRedisScript<>(luaScript, Long.class);
        //删除锁，保证原子性
        Long lock1 = stringRedisTemplate.execute(script, Arrays.asList("lock"), uuid);
    }
    //加锁成功，检索DB
    return getCataLogJsonFromDb();
}else{
    return getCataLogJson();
}
```

#### Redisson 分布式锁框架

`https://github.com/redisson/redisson/wiki/Table-of-Content`

1. 引入依赖

```
        <dependency>
            <groupId>org.redisson</groupId>
            <artifactId>redisson</artifactId>
            <version>3.12.5</version>
        </dependency>
```

2. 配置Redisson

   ```java
   public class MyRedissonConfig {
   
       @Bean(destroyMethod="shutdown")
       public RedissonClient redisson() throws IOException {
           Config config = new Config();
   		config.useSingleServer().setAddress("redis://192.168.137.10:6379");
           return Redisson.create(config);
       }
   }
   ```

   可重入锁：A方法调用B方法，A对资源加了lock1，B也要对相同的资源加lock1，但A已经加了，B就可以拿来用了，B执行完，A执行完释放lock1。避免引起死锁。所有的锁都应该设计为可重入锁。

   可重入就是说某个线程已经获得某个锁，可以再次获取锁而不会出现死锁。

3.使用redisson，默认加锁30秒

```java
        // 获取一把锁，只要名字一样，就是同一把锁
        RLock mylock = redisson.getLock("mylock");
        mylock.lock();
        try{
            System.out.println("业务代码");
        }finally {
            mylock.unlock();
        }
```

redisson解决了两个问题

- 自动续期，如果锁业务超长，运行期间自动给锁续上新的30秒，不用担心过期的问题。
- 加锁的业务运行完成，不会给锁续期，即使不手动解锁，默认30秒以后自动删除。

读写锁

写锁是一个排他锁，读锁是共享锁，写锁没释放，读必须等待

- 写 + 读：等待写锁释放

- 写 + 写：阻塞方式

- 读 + 写：有读锁，写需要等待

- 读 + 读：相当于无锁，并发读，只会在redis记录好当前的读锁，会同时加锁成功

  只要有写的存在，都必须等待

信号量

使用场景：停车场有多个车位，当都停满的时候，新车停不进来，当走了一辆以后，新车才可以进来。

```java
    @GetMapping("/park")
    @ResponseBody
    public String park() throws InterruptedException {
        RSemaphore park = redisson.getSemaphore("park");
        //park.acquire();//获取一个信号，是阻塞
        boolean b = park.tryAcquire();//尝试获取一个信号，不是阻塞
        return "ok=>"+b;
    }

    @GetMapping("/leave")
    @ResponseBody
    public String leave(){
        RSemaphore park = redisson.getSemaphore("park");
        park.release();//释放信号，也是阻塞
        return "ok";
    }
```

信号量也可以用作系统的限流，控制每秒最大访问量。

闭锁（CountDownLatch）

跟java闭锁相似。

使用场景：学校放假，锁大门。所有班级学生都离开，才可以锁大门。

```java
    @GetMapping("/lockDoor")
    @ResponseBody
    public String lockDoor() throws InterruptedException {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5);
        door.await();//等待闭锁都完成，阻塞

        return "ok";
    }

    @GetMapping("/left/{id}")
    @ResponseBody
    public String left(@PathVariable("id") Long id){
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.countDown();
        return id+" Class left";
    }
```

缓存一致性问题

解决方案：

1. 双写模式：数据更新的同时，更新缓存

2. 失效模式：数据更新的同时，删除缓存

   本系统的一致性解决方案： 

   1、缓存的所有数据都有过期时间，数据过期下一次查询触发主动更新 

   2、读写数据的时候，加上分布式的读写锁。 经常写，经常读

## SpringCache

官网：`https://docs.spring.io/spring/docs/current/spring-framework-reference/integration.html#cache`

```
主要的注解，一定要加到serverImpl类的@Override方法上
@Cacheable: 触发保存缓存的操作
@CacheEvict: 触发将数据从缓存中删除，失效模式
@CachePut: 不影响方法执行，更新缓存，双写模式
@Caching: 组合以上多个操作
@CacheConfig: 在一个类中，共享缓存的相同配置
```

### 整合SpringCache，简化缓存开发

1. 引入依赖

   ```xml
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-cache</artifactId>
           </dependency>
   ```

2. 写配置

   已经完成的自动配置

   - CacheAutoConfiguration会导入RedisCacheConfiguration，自动配好了RedisCacheManager

   - 配置使用redis作为缓存

     ```properties
     spring.cache.type=redis
     ```

### 测试缓存

- 开启缓存功能 `@EnableCaching`在Application类中。

- @Cacheable，代表当前方法的结果需要被缓存，如果缓存中有，该方法都不需要被调用，如果没 有，该方法会被执行，将结果放入缓存。

- 每一个需要缓存的数据，都要指定要放入哪个名字的缓存中【缓存分区（按业务类型分）】。

  ```
  @Cacheable({"category"})
  ```

- 默认行为
  - key是默认生成的，缓存的名字::SimpleKey []
  - 缓存的Value值，默认使用jdk序列化机制，将序列化后的数据存入redis
  - 默认时间是TTL=-1，永不过期。

- 将默认行为，修改为自定义行为

  - 指定缓存的key，使用key属性，接收一个spEL

    ```java
    @Cacheable(value = {"category"},key = "#root.methodName")
    ```

  - 指定缓存过期时间，在配置文件中个修改，以毫秒为单位

    ```properties
    spring.cache.redis.time-to-live=3600000
    #缓存key的前缀，如果指定，就使用，否则使用缓存名字。
    #使用分区名作为前缀，这样可以按分区删除
    spring.cache.redis.key-prefix=CACHE_ 
    spring.cache.redis.use-key-prefix=true
    #是否缓存空值，防止穿透
    spring.cache.redis.cache-null-values=true
    ```

  - 将数据保存为Json，将RedisCacheConfiguration注入到Spring容器中，修改默认配置。

    ```java
    @EnableConfigurationProperties(CacheProperties.class)
    @Configuration
    @EnableCaching
    public class MyCacheConfig {
    
        @Bean
        RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){
    
            RedisCacheConfiguration config  = RedisCacheConfiguration.defaultCacheConfig();
            config = config.entryTtl(Duration.ofMinutes(5));
    
            CacheProperties.Redis redisProperites = cacheProperties.getRedis();
            if(!redisProperites.isCacheNullValues()){
                config =config.disableCachingNullValues();
            }
            
    
            config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
            config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
    
            return config;
        }
    }
    ```

    

- 原理

  CacheAutoConfiguration -> RedisCacheConfiguration -> RedisCacheManager -> 初始化所有的缓存 -> 每个缓存决定使用什么配置，已有的就用，没有就使用默认的。如果想改缓存配置，给容器中放入一个RedisCacheConfiguration 类，就会应用到当前的缓存管理器。

- 数据更新，缓存自动失效

  ```java
  @CacheEvict(value={"category"},key = "'getLevel1Categorys'")
  ```

- 同时进行多次缓存操作

  ```java
      @Caching(evict = {
              @CacheEvict(value={"category"},key = "'getLevel1Categorys'"),
              @CacheEvict(value={"category"},key = "'getCataLogJson'")
      })
  ```

  也可以删除分区下所有的key

  ```java
  @CacheEvict(value={"category"},allEntries = true)
  ```

### SpringCache的不足

### 读模式

1. 缓存穿透

   解决方案：默认配置cache-null-value=true

2. 缓存击穿

   默认是不加锁的，可以使用sync=true，防止击穿，这是本地锁，不是分布式锁。

   ```java
   @Cacheable(value = {"category"},key = "#root.methodName",sync=true)
   ```

3. 缓存雪崩

   解决方案：不是超大型项目，不会出现大量的缓存同时过期，因为存储缓存的时间也不同。默认配置spring.cache.redis.time-to-live=3600000

### 写模式

1. 读写加锁
2. 引入canal，感知mysql的更新去更新缓存
3. 读多写多，直接去DB查询

### 总结

读多写少，及时性一致性要求不高的数据，完全可以使用SpringCache；写模式，只要缓存有过期时间，就可以了。

特殊数据：需要特殊设计

## CompletableFuture异步编排

无

## SpringMVC视图映射

不必通过Controller跳转，默认只支持get

```java
@Configuration
public class EmallWebConfig implements WebMvcConfigurer {

    @Override
    public void addViewControllers(ViewControllerRegistry registry){
        registry.addViewController("/login.html").setViewName("login");
        registry.addViewController("/reg.html").setViewName("reg");
    }
}
```

## 使用阿里云短信服务

在阿里云->云市场->短信，购买短信服务

APPCODE在云市场->已购买的服务找到APPCODE

请求Header中添加的Authorization字段；配置Authorization字段的值为“APPCODE ＋ 半角空格 ＋APPCODE值”。
例：Authorization:APPCODE 3F2504E04F8911D39A0C0305E82C3301

### 绑定配置文件

```java
@ConfigurationProperties(prefix = "spring.cloud.alicloud.sms")
@Data
@Component
public class SmsComponent {

    private String host;
    private String path;
    private String appcode;
```

```yaml
spring:
  cloud:
    alicloud:
      sms:
        host: https://zwp.market.alicloudapi.com
        path: /sms/sendv2
        appcode: 45c3abc99aa04bae9ff74c1c38e0cefa
```

```js
$(function(){
    $("#sendCode").click(function(){
        if ( $(this).hasClass("disabled") ) return;
        //发送验证码
        $.get("/sms/sendCode?phone="+$("#phoneNum").val(),function(data){
            if(data.code !=0 ){
                alert(data.msg);
            }
        });
        //倒计时
        timeoutChangeStyle();
    });
})
var num = 10;
function timeoutChangeStyle() {
    $("#sendCode").attr("class","disabled");
    if ( num == 0 ){
        $("#sendCode").text("发送验证码");
        num = 10;
        $("#sendCode").attr("class","");
    }else {
        var str = num + "s 后再次发送";
        $("#sendCode").text(str);
        setTimeout("timeoutChangeStyle()", 1000);
        num--;
    }
}
```



## 用户注册

Controller

```java

    @PostMapping("/regist")
    public String regist(@Valid UserRegistVo vo, BindingResult result, RedirectAttributes redirectAttributes){

        if(result.hasErrors()){
            Map<String,String> errors = result.getFieldErrors().stream().collect(Collectors.toMap(FieldError::getField, FieldError::getDefaultMessage));
            redirectAttributes.addFlashAttribute("errors",errors);
            //校验出错，回到注册页
            return "redirect:http://auth.emall.com/reg.html";
        }
        //真正注册，调用远程服务
        //注册成功回登录页
        return "redirect:http://auth.emall.com/login.html";
    }
```

#### 微博登录

https://open.weibo.com/wiki/Connect/login

- App Key：2350946709

- App Secret：a989fd1f900ad1f2d16bc3c3b8680765

换取的code码，只能换取一次access token，之后失效。

换取后的access token一段时间有效，以后通过携带access token可以访问远程资源服务器开放的所有api，通过api得到用户相关信息，并保存到本系统的数据库中，包括access token。

### 分布式session

不同的域名，不共享session。比如auth.emall.com和emall.com。

分布式环境下，即使同一服务，在不同的服务器上，session也会不同步。

#### 解决方案

1. session复制
2. 客户端存储
3. hash一致性   √
4. 统一存储 √   SpringSession

#### 子域session共享  

不同服务，子域session共享  

jsessionid这个cookie默认是当前系统域名的。当我们分拆服务，不同域名部署的时候，我们可以设置Cookies的作用域为指定的父域名，即使子域名设置Cookies的时候，也能让父域名直接使用，这样就可以让浏览器跨不同的微服务，可以通用，而session内容又统一存储到redis中，就可以解决session共享和子域session共享问题。

父域名：emall.com

子域名：auth.emall.com ,  order.emall.com

### SpringSession

整合SpringSession

1. application.properties

   ```properties
   spring.session.store-type=redis
   server.servlet.session.timeout=30m
   ```

2. 注解

   ```java
   @EnableRedisHttpSession
   ```

使用SpringSession

1. 设置session存储的数据

   ```java
   session.setAttribute("loginUser",data);
   ```

2. 页面获取session数据

   ```html
   <a href="http://auth.emall.com/login.html" th:text="${session.loginUser == null ? '你好，请登录' : '你好:'+session.loginUser.username}"></a>
   ```

3. 配置redis存储json，而不是序列化后的ASC码，设置session的跨域

   ```java
   @Configuration
   public class EmallSessionConfig {
   
       @Bean
       public CookieSerializer cookieSerializer() {
           DefaultCookieSerializer serializer = new DefaultCookieSerializer();
           serializer.setDomainName("emall.com");//设置session作用域，放大到父域
           serializer.setCookieName("EMALLSESSIONID");
           return serializer;
       }
   
       @Bean
       public RedisSerializer<Object> springSessionDefaultRedisSerializer() {
           return new GenericFastJsonRedisSerializer();
           //redis存储json
       }
   }
   ```

   该配置类要放到auth和product工程中，不能放到common中，否则无效。

### 单点登录

单点登录框架`https://gitee.com/xuxueli0323/xxl-sso?_from=gitee_search`

1. 中央认证服务器：ssoserver.com
2. 其他系统，想要登录去ssoserver.com登录，登录成功跳转回来
3. 只要有一个系统登录，其他都不需要登录
4. 全系统统一一个唯一标识cookies，所有系统域名可能都不相同

实现核心

1. 给登录服务器留下登录痕迹，即Cookies

2. 登录服务器要将token信息重定向的时候，带上url，服务器将uuid作为key，用户信息作为value存储到redis中

3. 其他系统要处理url地址上的关键token，只要有，带上token向服务器发请求，服务器接到请求后，用token从redis中得到对应的用户信息，返回给系统，系统得到用户信息后，保存在自己的session中。

4. cookies不能跨浏览器

## 购物车

浏览器有一个cookie:user-key:标识用户身份，一个月后到期
如果第一次使用购物车功能，都会给用户一个临时身份
浏览器以后保存，每次访问都会带上这个cookie
登录的话，session里有
没登录，按照cookie里面带的user-key来做
第一次如果没有临时用户，需要创建一个临时用户。

ThreadLocal 同一线程共享数据 原理：Map<ThreadId,Object>

Interceptor -> Controller -> service -> dao都是同一个线程

创建拦截器

```java
@Component
public class CartInterceptor implements HandlerInterceptor {
    public static  ThreadLocal<UserInfoTo> threadLocal = new ThreadLocal<>();

    /**
     * 目标方法执行之前拦截
     */
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
                threadLocal.set(userInfoTo);
    }
     /**
     * 业务执行之后
     */
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        UserInfoTo userInfoTo = threadLocal.get();

        if( !userInfoTo.isTempUser()) {
            //创建Cookie name：value
            Cookie cookie = new Cookie(CartConstant.TEMP_USER_COOKIE_NAME, userInfoTo.getUserKey());
            //设置作用域
            cookie.setDomain("emall.com");
            cookie.setMaxAge(CartConstant.TEMP_USER_COOKIE_TIMEOUT);//设置过期时间
            response.addCookie(cookie);
        }
    }
```

配置拦截器

```java
@Configuration
public class EmallWebConfig implements WebMvcConfigurer {

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new CartInterceptor())
                .addPathPatterns("/**");
    }
}
```

多线程调用远程接口

```java
@Autowired
ThreadPoolExecutor executor;

CompletableFuture<Void> skuInfoTask = CompletableFuture.runAsync(() -> {
    //远程查询要添加的商品信息
    R r = productFeignService.getSkuInfo(skuId);
    SkuInfoVo skuInfo = r.getData("skuInfo", new TypeReference<SkuInfoVo>() {
    });
},executor);

CompletableFuture.allOf(skuInfoTask).get();
```

将线程池注入到spring容器

```java
@Configuration
public class MyThreadConfig {
    @Bean
    public ThreadPoolExecutor threadPoolExecutor(ThreadPoolConfigProperties pool){
        return new ThreadPoolExecutor(
                pool.getCoreSize(),
                pool.getMaxSize(),
                pool.getKeepAliveTime(),
                TimeUnit.SECONDS,new LinkedBlockingDeque<>(100000),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy()
        );
    }
}
```

避免购物车重复添加

解决方案：通过添加完购物车，重定向到一个查询的URL，这样每次页面刷新，都是查询操作。

RedirectAttributes.addFlashAttribute()   将数据放到session，只能取得一次。

RedirectAttributes.addAttribute()   将数据放到url后面。

```java
    @PostMapping("/addToCart")
    public String addToCart(@RequestParam("skuId") Long skuId,
                            @RequestParam("num") Integer num,
                            RedirectAttributes ra) throws  {

        cartService.addToCart(skuId,num);
        ra.addAttribute("skuId",skuId);
        return "redirect:/addToCartSuccess.html";
    }

    @GetMapping("/addToCartSuccess.html")
    public String addToCartSuccessPage(@RequestParam("skuId") Long skuId,Model model){
        CartItem item = cartService.getCartItem(skuId);
        model.addAttribute("item",item);

        return "success";
    }
```

动态改变购物车的商品选择，更新到redis

```html
//定义一个skuId属性，并赋值
<li><input type="checkbox" th:attr="skuId=${item.skuId}" class="itemCheck" th:checked="${item.check}"></li>
```

```javascript
    $(".itemCheck").click(function(){
        var skuId = $(this).attr("skuId");
        var check = $(this).prop("checked");
        location.href="http://cart.emall.com/checkItem?skuId="+skuId+"&check="+(check?1:0);
    })
```

```java
    @GetMapping("/checkItem")
    public String checkItem(@RequestParam("skuId") Long skuId,@RequestParam("check") Integer check){
        cartService.checkItem(skuId,check);
        return "redirect:http://cart.emall.com/cartList.html";
    }
```

## RabbitMQ

>  是一个专门做队列的框架，在队列方面要比redies队列性能要好，支持的功能会更多，消息的可靠性更强，可以根据路由规则去选择进入哪一个队列，做到更加细致的消息分发，同是可以做到消息响应，当处理一个比较耗时得任务的时候，也许想知道消费者（consumers）是否运行到一半就挂掉。在当前的代码中，当RabbitMQ将消息发送给消费者（consumers）之后，马上就会将该消息从队列中移除。此时，如果把处理这个消息的工作者（worker）停掉，正在处理的这条消息就会丢失。同时，所有发送到这个工作者的还没有处理的消息都会丢失。

应用场景

1. 异步处理
2. 应用解耦
3. 流量控制

消息代理（message broker）和目的地（destination）

当消息发送者发送消息以后，将由消息代理接管，消息代理保证消息传递到指定目的地。

消息目的地

1. 队列（queue）：点对点消息通信（point-to-point）
2. 主题（topic）：发布（publish）/订阅（subscribe）消息通信

点对点：消息只有唯一的发送者和接收者，但不能说只有一个接收者。

发布订阅：发送者发送消息到主题，多个接收者监听这个主题，那么就会在消息到达时同时收到消息。

JMS（Java Message Service ）

定义Java api层面的标注，在Java体系中，多个client均可以通过JMS进行交互，不需要应用修改代码，但对跨语言支持较差。ActiveMQ作为实现者。

AMQP（Advanced Message Queue Protol）

使用json作为传输对象，具有跨平台、跨语言的特性。RabitMQ

#### Docker安装RabbitMQ

官方文档`https://www.rabbitmq.com/networking.html`

```
docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 rabbitmq:management
#开机自动启动
docker update rabbitmq --restart=always
#控制台
http://192.168.137.10:15672/
guest/guest
```

Exchange类型

- direct:路由键与队列名完全匹配。单播模式或点对点模式

- fanout（扇出）:广播类型或发布订阅模式，不关心路由键，消息被转发到与该交换机绑定的所有队列。

- topic:将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。[#]匹配0个或多个单词，[*]匹配一个单词。usa.news -> usa.#  和 #.news

### Springboot整合RabbitMQ

1. 引入`spring-boot-starter-amqp`

2. 自动注入`RabbitMessagingTemplate`，`RabbitTemplate`,`AmqpAdmin`,`CachingConnectionFactory`

3. @EnableRabbit

4. ```properties
   spring.rabbitmq.host=192.168.137.10
   spring.rabbitmq.port=5672
   spring.rabbitmq.virtual-host=/
   ```

5. 测试代码

   ```java
       @Autowired
       AmqpAdmin amqpAdmin;
   
       @Test
       void createExchange() {
           DirectExchange directExchange = new DirectExchange("hello-java-exchange",true,false);
           amqpAdmin.declareExchange(directExchange);
       }
   
       @Test
       void createQueue(){
           Queue queue = new Queue("hello-java-queue",true,false,false);
           amqpAdmin.declareQueue(queue);
       }
   
       @Test
       void createBinding(){
           Binding binding = new Binding("hello-java-queue", Binding.DestinationType.QUEUE,"hello-java-exchange","hello.java",null);
           amqpAdmin.declareBinding(binding);
       }
   
   ```

6. 发送消息

   ```java
       @Autowired
       RabbitTemplate rabbitTemplate;
   
       @Test
       //最后一个参数，是消息的唯一ID，当发送失败的时候，replyCode会返回这个ID
       void sendMsg(){
           User user = new User();
           user.setId("1");
           user.setName("wh");
           rabbitTemplate.convertAndSend("hello-java-exchange","hello.java",user, new CorrelationData(UUID.randomUUID().toString()));
       }
   ```
```
   
配置Converter
   
   ```java
   @Configuration
   public class MyRabbitConfig {
       @Bean
       public Jackson2JsonMessageConverter messageConverter(){
           return new Jackson2JsonMessageConverter();
       }
   }
```

7. 接收消息

   @RabbitListener  标注在类和方法，监听哪个队列

   ```java
       @RabbitListener(queues = "hello-java-queue")
       public void receiveMsg(Message msg, User content){
           System.out.println(content);
       }
   ```

   @RabbitHanndler  可以接收不同类型的消息

   ```
       @RabbitHanndler
       public void receiveMsg(Message msg, User1 content1){
           System.out.println(content);
       }
       @RabbitHanndler
       public void receiveMsg(Message msg, User2 content2){
           System.out.println(content);
       }
   ```

   #### 可靠送达

   `https://www.rabbitmq.com/reliability.html`

   p(生产者）->  b(broker)  :  confirmCallback 确认模式

   e(交换机)  ->  q(队列)  :  returnCallback 未投递到queue(投递失败)退回模式

   q(队列)   ->   c(消费者)  :  ack ack机制

   ##### 发送端确认

   1. 添加配置

      ```properties
      spring.rabbitmq.publisher-confirm=true
      ```

   2. 设置回调

      ```java
       //MyRabbitConfig对象创建完成后，调用
          @PostConstruct
          public void initRabbitTemplate(){
              rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
                  /**
                   * 只要消息成功抵达Queue，b就是true
                   * @param correlationData 当前消息的唯一关联数据（这个消息的唯一Id）
                   * @param ack 消息是否成功收到
                   * @param s 失败的原因
                   */
                  @Override
                  public void confirm(CorrelationData correlationData, boolean ack, String s) {
                      System.out.println("ack="+ack);
                  }
              });
      
              rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
                  /**
                   * 只要消息没有投递到指定的队列，就触发这个失败回调
                   * @param message 投递失败的消息详细信息
                   * @param i 回复的状态码
                   * @param s 回复的文本内容
                   * @param s1 当时这个消息发给哪个交换机
                   * @param s2 当时这个消息用哪个路由键
                   */
                  @Override
                  public void returnedMessage(Message message, int i, String s, String s1, String s2) {
                      System.out.println("fail message:"+message);
                  }
              });
          }
      ```

   ##### 消费端确认
   
   默认自动确认，只要消息接收到，客户端会自动确认，服务端会移除这个消息。
   
   问题：收到很多消息，自动回复给服务器ack，只有一个消息处理完成，如果出现异常，消息全部丢失。
   
   消费者手动确认：只要程序没有明确通知服务器ack，消息一致是unack状态，即使consumer出现异常，消息也不会丢失，消息会变为ready状态，等待下一次接收。
   
   ```properties
   spring.rabbitmq.listener.simple.acknowledge-mode=manual
   ```
   
   ```java
       @RabbitListener(queues = "hello-java-queue")
       public void receiveMsg(Message msg, User content, Channel channel) throws IOException {
           System.out.println(content);
           //按顺序自增
           long deliveryTag = msg.getMessageProperties().getDeliveryTag();
           //非批量签收
           channel.basicAck(deliveryTag,false);
           //拒绝签收
           //channel.basicNack(deliveryTag,false,false);
       }
   ```
   
   



